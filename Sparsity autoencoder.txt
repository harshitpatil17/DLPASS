import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
import numpy as np
import matplotlib.pyplot as plt

(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

x_train = x_train.reshape((len(x_train), 784))
x_test = x_test.reshape((len(x_test), 784))

encoding_dim = 64  # Size of the latent space

input_img = layers.Input(shape=(784,))
# Encoder
encoded = layers.Dense(256, activation='relu')(input_img)
encoded = layers.Dense(
    encoding_dim,
    activation='sigmoid',  # sigmoid keeps activations in (0,1) for sparse reg
    activity_regularizer=regularizers.l1(1e-5)  # smaller L1 -> less aggressive sparsity
)(encoded)


decoded = layers.Dense(256, activation='relu')(encoded)
decoded = layers.Dense(784, activation='sigmoid')(decoded)

autoencoder = models.Model(input_img, decoded)

encoder = models.Model(input_img, encoded)

autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

history = autoencoder.fit(
    x_train, x_train,
    epochs=50,
    batch_size=256,
    shuffle=True,
    validation_data=(x_test, x_test),
    verbose=2
)

encoded_imgs = encoder.predict(x_test)
decoded_imgs = autoencoder.predict(x_test)


n = 10  # number of digits to display
plt.figure(figsize=(20, 4))
for i in range(n):
    # Original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title("Original")
    plt.axis('off')

    # Reconstructed
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')
    plt.title("Reconstructed")
    plt.axis('off')

plt.show()

sparsity = np.mean(np.abs(encoded_imgs) < 0.05)
print(f"\nSparsity (fraction of near-zero activations): {sparsity*100:.2f}%")